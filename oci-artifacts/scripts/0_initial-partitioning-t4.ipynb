{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e2a73d-785d-405d-818f-0541a5478574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install boto3==1.35.95 botocore==1.35.95 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f3583-cdd5-457f-90b0-f1958fba92a6",
   "metadata": {},
   "source": [
    "# Initial Partitioning (4 tiles)\n",
    "\n",
    "split the original PASTIS dataset into 4 per-tile subsets, package each tile into a tar archive, and upload them individually to an S3 bucket.\n",
    "\n",
    "- dataset origin: https://github.com/VSainteuf/pastis-benchmark\n",
    "- data source: https://www.eotdl.com/datasets/PASTIS-HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463befb7-7346-408c-950a-2fb934629033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"pastis.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb9ef55-403f-4481-a62c-55175596a5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42312221-bb07-4400-bc99-c60b03355052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_geojson_ids_and_tiles(path: Path, max_items: int = None) -> Dict[str, str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        geojson = json.load(f)\n",
    "\n",
    "    features = geojson.get(\"features\", [])\n",
    "    if max_items is not None:\n",
    "        features = features[:max_items]\n",
    "\n",
    "    id_to_tile = {}\n",
    "    for feature in features:\n",
    "        id_ = feature[\"id\"]\n",
    "        tile = feature.get(\"properties\", {}).get(\"TILE\", \"UNKNOWN\")\n",
    "        id_to_tile[id_] = tile\n",
    "    return id_to_tile\n",
    "\n",
    "def find_files_with_ids_and_tiles(base_path: Path, id_to_tile: Dict[str, str]) -> Dict[str, List[Tuple[str, Path]]]:\n",
    "    results = {id_: [] for id_ in id_to_tile}\n",
    "\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if 'aux' in file.lower() or file.lower().startswith('zones_'):\n",
    "                continue\n",
    "            for id_ in id_to_tile:\n",
    "                if id_ in file:\n",
    "                    full_path = Path(root) / file\n",
    "                    rel_path = full_path.relative_to(base_path)\n",
    "                    tile = id_to_tile[id_]\n",
    "                    arcname = str(Path(tile) / id_ / rel_path.name)\n",
    "                    results[id_].append((arcname, full_path))\n",
    "    return results\n",
    "\n",
    "BASE_DIR = Path(os.getenv(\"BASE_DIR\"))\n",
    "id_to_tile = load_geojson_ids_and_tiles(Path(os.getenv(\"BASE_DIR\")) / \"metadata_pastis.geojson\") #, 100) # 2433 in total)\n",
    "matched_files = find_files_with_ids_and_tiles(BASE_DIR, id_to_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322b532f-1f0c-4672-b506-7b45a7938cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Patch count per TILE:\n",
      " - t30uxv: 531 patches\n",
      " - t31tfj: 623 patches\n",
      " - t31tfm: 723 patches\n",
      " - t32ulu: 556 patches\n",
      "\n",
      "üî¢ Total unique tiles: 4\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tile_counts = defaultdict(int)\n",
    "\n",
    "for id_, path_pairs in matched_files.items():\n",
    "    if not path_pairs:\n",
    "        continue\n",
    "\n",
    "    # Extract tile name from the arcname (assumes structure TILE/id_/filename)\n",
    "    first_arcname = path_pairs[0][0]\n",
    "    tile = Path(first_arcname).parts[0]\n",
    "    tile_counts[tile] += 1\n",
    "\n",
    "print(\"\\nüì¶ Patch count per TILE:\")\n",
    "for tile, count in sorted(tile_counts.items()):\n",
    "    print(f\" - {tile}: {count} patches\")\n",
    "\n",
    "print(f\"\\nüî¢ Total unique tiles: {len(tile_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4884b809-1003-4922-bc41-14358eaefdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bucket 'versioneer-papers' is accessible and writable.\n",
      "‚è≠Ô∏è Skipping t30uxv: already exists in S3.\n",
      "- t31tfj: 4984 files\n",
      "‚úÖ Uploaded: https://s3.de.io.cloud.ovh.net/versioneer-papers/pastis/t31tfj.tar (4984 files)\n",
      "- t31tfm: 5784 files\n",
      "‚úÖ Uploaded: https://s3.de.io.cloud.ovh.net/versioneer-papers/pastis/t31tfm.tar (5784 files)\n",
      "- t32ulu: 4448 files\n",
      "‚úÖ Uploaded: https://s3.de.io.cloud.ovh.net/versioneer-papers/pastis/t32ulu.tar (4448 files)\n",
      "\n",
      "üì¶ Tiles uploaded: 3 (skipped: 1)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#print(\"boto3 version:\", boto3.__version__)\n",
    "#print(\"botocore version:\", botocore.__version__)\n",
    "\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "BUCKET_PREFIX = os.getenv(\"BUCKET_PREFIX\", \"\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"\")\n",
    "AWS_ENDPOINT_URL = os.getenv(\"AWS_ENDPOINT_URL\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "#print(BUCKET_NAME)\n",
    "\n",
    "missing = [v for v in [\"BUCKET_NAME\", \"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\"] if not os.getenv(v)]\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"Missing required env vars: {', '.join(missing)}\")\n",
    "\n",
    "boto_config = Config(\n",
    "    s3={'addressing_style': 'path'},\n",
    "    retries={'max_attempts': 3},\n",
    "    signature_version='s3v4'\n",
    ")\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    endpoint_url=AWS_ENDPOINT_URL,\n",
    "    region_name=AWS_REGION,\n",
    "    config=boto_config\n",
    ")\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "\n",
    "    test_key = f\"{BUCKET_PREFIX.rstrip('/')}/test.txt\" if BUCKET_PREFIX else \"test.txt\"\n",
    "    s3.put_object(Bucket=BUCKET_NAME, Key=test_key, Body=b\"test\")\n",
    "    s3.delete_object(Bucket=BUCKET_NAME, Key=test_key)\n",
    "\n",
    "    print(f\"‚úÖ Bucket '{BUCKET_NAME}' is accessible and writable.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå Bucket check failed: {e}\")\n",
    "\n",
    "tile_to_paths = defaultdict(list)\n",
    "for id_, path_pairs in matched_files.items():\n",
    "    for arcname, path in path_pairs:\n",
    "        tile = Path(arcname).parts[0]\n",
    "        tile_to_paths[tile].append((arcname, path))\n",
    "\n",
    "skipped = 0\n",
    "uploaded = 0\n",
    "\n",
    "for tile, file_list in tile_to_paths.items():\n",
    "    if not file_list:\n",
    "        continue\n",
    "\n",
    "    s3_key = f\"{BUCKET_PREFIX.rstrip('/')}/{tile}.tar\" if BUCKET_PREFIX else f\"{tile}.tar\"\n",
    "\n",
    "    try:\n",
    "        s3.head_object(Bucket=BUCKET_NAME, Key=s3_key)\n",
    "        print(f\"‚è≠Ô∏è Skipping {tile}: already exists in S3.\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] != \"404\":\n",
    "            raise RuntimeError(f\"‚ùå Error checking existence of {s3_key}: {e}\")\n",
    "\n",
    "    print(f\"- {tile}: {len(file_list)} files\")\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".tar\", delete=True) as tmp_tar:\n",
    "        with tarfile.open(tmp_tar.name, \"w\") as tar:\n",
    "            for arcname, path in file_list:\n",
    "                tar.add(Path(path), arcname=arcname)\n",
    "                \n",
    "        s3.upload_file(tmp_tar.name, BUCKET_NAME, s3_key)\n",
    "        url_display = f\"{AWS_ENDPOINT_URL}/{BUCKET_NAME}/{s3_key}\"\n",
    "        uploaded += 1\n",
    "        print(f\"‚úÖ Uploaded: {url_display} ({len(file_list)} files)\")\n",
    "\n",
    "print(f\"\\nüì¶ Tiles uploaded: {uploaded} (skipped: {skipped})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default *",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
