{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da737c5-3ef4-4b38-b5b1-defda5e1154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install boto3==1.35.95 botocore==1.35.95 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f3583-cdd5-457f-90b0-f1958fba92a6",
   "metadata": {},
   "source": [
    "# Initial Partitioning (2433 patches)\n",
    "\n",
    "split the original PASTIS dataset into 2433 per-patch subsets, package each patch into a tar archive, and upload them individually to an S3 bucket.\n",
    "\n",
    "- dataset origin: https://github.com/VSainteuf/pastis-benchmark\n",
    "- data source: https://www.eotdl.com/datasets/PASTIS-HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463befb7-7346-408c-950a-2fb934629033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"pastis.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb9ef55-403f-4481-a62c-55175596a5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42312221-bb07-4400-bc99-c60b03355052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_geojson_ids(path: Path, max_items: int = None) -> List[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        geojson = json.load(f)\n",
    "    \n",
    "    features = geojson.get(\"features\", [])\n",
    "    ids = [feature[\"id\"] for feature in features]\n",
    "    \n",
    "    if max_items is not None:\n",
    "        ids = ids[:max_items]\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def find_files_with_ids(base_path: Path, ids: List[str]) -> Dict[str, List[Path]]:\n",
    "    results = {id_: [] for id_ in ids}\n",
    "    \n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if 'aux' in file.lower() or file.lower().startswith('zones_'):\n",
    "                continue\n",
    "            for id_ in ids:\n",
    "                if id_ in file:\n",
    "                    results[id_].append(Path(root) / file)\n",
    "    \n",
    "    return results\n",
    "\n",
    "BASE_DIR = Path(os.getenv(\"BASE_DIR\"))\n",
    "geojson_ids = load_geojson_ids(Path(os.getenv(\"BASE_DIR\")) / \"metadata_pastis.geojson\") #, 100) # 2433 in total\n",
    "matched_files = find_files_with_ids(BASE_DIR, geojson_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322b532f-1f0c-4672-b506-7b45a7938cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches with exactly 8 files: 2433\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "count = 0\n",
    "for id_, paths in matched_files.items():\n",
    "    if len(paths) == 8:  # Expect exactly 8 files per patch\n",
    "        count += 1\n",
    "    else:\n",
    "        print(f\"{id_} MISMATCH - found {len(paths)} files\")\n",
    "        for path in paths:\n",
    "            print(f\"  {path}\")\n",
    "            path = Path(path)\n",
    "\n",
    "            if path.suffix == \".npy\":\n",
    "                da = xr.DataArray(np.load(path), name=path.stem)\n",
    "                print(da.shape)\n",
    "            elif path.suffix == \".tif\":\n",
    "                try:\n",
    "                    import rioxarray\n",
    "                    da = rioxarray.open_rasterio(path)\n",
    "                    print(da.shape)\n",
    "                except ImportError:\n",
    "                    pass  # silently skip if rioxarray is not available\n",
    "\n",
    "print(f\"Number of patches with exactly 8 files: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4884b809-1003-4922-bc41-14358eaefdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bucket 'versioneer-papers' is accessible and writable.\n",
      "Number of patches uploaded: 0 (skipped: 2433)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#print(\"boto3 version:\", boto3.__version__)\n",
    "#print(\"botocore version:\", botocore.__version__)\n",
    "\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "BUCKET_PREFIX = os.getenv(\"BUCKET_PREFIX\", \"\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"\")\n",
    "AWS_ENDPOINT_URL = os.getenv(\"AWS_ENDPOINT_URL\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "#print(BUCKET_NAME)\n",
    "\n",
    "missing = [v for v in [\"BUCKET_NAME\", \"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\"] if not os.getenv(v)]\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"Missing required env vars: {', '.join(missing)}\")\n",
    "\n",
    "boto_config = Config(\n",
    "    s3={'addressing_style': 'path'},\n",
    "    retries={'max_attempts': 3},\n",
    "    signature_version='s3v4'\n",
    ")\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    endpoint_url=AWS_ENDPOINT_URL,\n",
    "    region_name=AWS_REGION,\n",
    "    config=boto_config\n",
    ")\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "\n",
    "    test_key = f\"{BUCKET_PREFIX.rstrip('/')}/test.txt\" if BUCKET_PREFIX else \"test.txt\"\n",
    "    s3.put_object(Bucket=BUCKET_NAME, Key=test_key, Body=b\"test\")\n",
    "    s3.delete_object(Bucket=BUCKET_NAME, Key=test_key)\n",
    "\n",
    "    print(f\"✅ Bucket '{BUCKET_NAME}' is accessible and writable.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ Bucket check failed: {e}\")\n",
    "\n",
    "skipped = 0\n",
    "uploaded = 0\n",
    "for id_, paths in matched_files.items():\n",
    "    if not paths:\n",
    "        continue\n",
    "        \n",
    "    s3_key = f\"{BUCKET_PREFIX.rstrip('/')}/{id_}.tar\" if BUCKET_PREFIX else f\"{id_}.tar\"\n",
    "\n",
    "    try:\n",
    "        s3.head_object(Bucket=BUCKET_NAME, Key=s3_key)\n",
    "        #print(f\"⏭️ Skipping {id_}: already exists in S3.\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] != \"404\":\n",
    "            raise RuntimeError(f\"❌ Error checking existence of {s3_key}: {e}\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".tar\", delete=True) as tmp_tar:\n",
    "        with tarfile.open(tmp_tar.name, \"w\") as tar:\n",
    "            for path in paths:\n",
    "                path = Path(path)\n",
    "                try:\n",
    "                    arcname = path.relative_to(BASE_DIR)\n",
    "                except ValueError:\n",
    "                    arcname = path.name\n",
    "                tar.add(path, arcname=arcname)\n",
    "\n",
    "        s3.upload_file(tmp_tar.name, BUCKET_NAME, s3_key)\n",
    "        url_display = f\"{AWS_ENDPOINT_URL}/{BUCKET_NAME}/{s3_key}\"\n",
    "        uploaded += 1\n",
    "        print(f\"✅ Uploaded: {url_display} ({len(paths)} files)\")\n",
    "        \n",
    "print(f\"Number of patches uploaded: {uploaded} (skipped: {skipped})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default *",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
